"""
åœ–ç‰‡å£“ç¸®å·¥å…· v4.0
éæ­·æŒ‡å®šç›®éŒ„åŠå­ç›®éŒ„ï¼Œå°‡åœ–ç‰‡å£“ç¸®å¾Œå¦å­˜æ–°æª”

åŠŸèƒ½:
- è‡ªè¨‚å£“ç¸®æ¯”ä¾‹ (--quality)
- ä¸¦è¡Œè™•ç†åŠ é€Ÿ (å¤šåŸ·è¡Œç·’)
- è¦†è“‹/è·³éå·²å­˜åœ¨æª”æ¡ˆ (--overwrite)
- ä¿ç•™ EXIF è³‡è¨Š (--keep-exif)
- è‡ªå‹•è·³éå£“ç¸®å¾Œè®Šå¤§çš„æª”æ¡ˆ
- Dry-run æ¨¡å¼é è¦½
- ç¸½ç©ºé–“ç¯€çœçµ±è¨ˆ
- æ”¯æ´æ·±åº¦æ§åˆ¶ (--max-depth)
- è·³éç„¡æ•ˆå£“ç¸®æ ¼å¼ (BMP)
"""

import re
from pathlib import Path
from functools import partial
from PIL import Image

from utils import (
    FileResult, collect_files, run_pipeline, print_summary,
    create_base_parser, resolve_directory, validate_quality,
    setup_logger, logger
)

# æ”¯æ´çš„åœ–ç‰‡æ ¼å¼
SUPPORTED_FORMATS = {'.jpg', '.jpeg', '.png', '.webp', '.bmp'}

# ç”¨æ–¼åµæ¸¬å·²å£“ç¸®æª”æ¡ˆçš„ regex pattern (e.g. _70%, _50%)
COMPRESSED_SUFFIX_PATTERN = re.compile(r'_\d+%$')


def get_exif(image: Image.Image) -> bytes | None:
    """å–å¾—åœ–ç‰‡çš„ EXIF è³‡æ–™"""
    try:
        return image.info.get('exif')
    except Exception:
        return None


def compress_image(
    filepath: Path, quality: int, overwrite: bool, keep_exif: bool, dry_run: bool
) -> FileResult:
    """å£“ç¸®å–®å¼µåœ–ç‰‡ä¸¦å¦å­˜æ–°æª”"""
    try:
        suffix = f"_{quality}%"
        
        # BMP ç›´æ¥è·³é
        if filepath.suffix.lower() == '.bmp':
            return FileResult('skipped', f"è·³é BMP (ä¸æ”¯æ´ç„¡ææˆ–æœ‰æå£“ç¸®): {filepath.name}")

        # æª¢æŸ¥æ˜¯å¦å·²ç¶“æ˜¯å£“ç¸®éçš„æª”æ¡ˆ (åŒ¹é…ä»»ä½• _æ•¸å­—% pattern)
        if COMPRESSED_SUFFIX_PATTERN.search(filepath.stem):
            return FileResult('skipped', f"è·³éå·²å£“ç¸®: {filepath.name}")

        # å»ºç«‹æ–°æª”å
        new_name = f"{filepath.stem}{suffix}{filepath.suffix}"
        new_path = filepath.parent / new_name

        # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å·²å­˜åœ¨
        if new_path.exists() and not overwrite:
            return FileResult('skipped', f"æª”æ¡ˆå·²å­˜åœ¨(è·³é): {new_name}")

        original_size = filepath.stat().st_size

        # Dry-run æ¨¡å¼
        if dry_run:
            return FileResult(
                'dry_run',
                f"[é è¦½] {filepath.name} -> {new_name} ({original_size / 1024:.1f}KB)",
            )

        # é–‹å•Ÿåœ–ç‰‡
        img = Image.open(filepath)
        exif_data = get_exif(img) if keep_exif else None

        # æº–å‚™å„²å­˜åƒæ•¸
        save_kwargs = {'optimize': True}

        if filepath.suffix.lower() in {'.jpg', '.jpeg', '.webp'}:
            save_kwargs['quality'] = quality
            if exif_data:
                save_kwargs['exif'] = exif_data
            if img.mode == 'RGBA':
                img = img.convert('RGB')
        elif filepath.suffix.lower() == '.png':
            pass  # PNG ä¸æ”¯æ´ qualityï¼Œä½¿ç”¨ optimize

        # åˆ¤æ–·è¼¸å‡ºæ ¼å¼
        ext = filepath.suffix.lower()
        format_map = {
            '.jpg': 'JPEG', '.jpeg': 'JPEG', '.png': 'PNG', '.webp': 'WEBP'
        }
        output_format = format_map.get(ext, 'JPEG')

        # å…ˆå­˜åˆ°æš«å­˜è·¯å¾‘æª¢æŸ¥å¤§å°
        temp_path = new_path.with_suffix('.tmp')
        img.save(temp_path, format=output_format, **save_kwargs)
        new_size = temp_path.stat().st_size

        # å£“ç¸®å¾Œåè€Œè®Šå¤§
        if new_size >= original_size:
            temp_path.unlink()
            return FileResult(
                'size_skip',
                f"å£“ç¸®å¾Œè®Šå¤§ï¼Œè·³é: {filepath.name} "
                f"({original_size / 1024:.1f}KB -> {new_size / 1024:.1f}KB)",
            )

        # é‡æ–°å‘½åç‚ºæ­£å¼æª”å
        if new_path.exists():
            new_path.unlink()
        temp_path.rename(new_path)

        reduction = (1 - new_size / original_size) * 100
        return FileResult(
            'success',
            f"âœ“ {filepath.name} -> {new_name} "
            f"({original_size / 1024:.1f}KB -> {new_size / 1024:.1f}KB, -{reduction:.1f}%)",
            original_size, new_size,
        )

    except Exception as e:
        return FileResult('failed', f"âœ— è™•ç†å¤±æ•— {filepath}: {e}")


def main():
    setup_logger()
    
    parser = create_base_parser(
        description='åœ–ç‰‡æ‰¹é‡å£“ç¸®å·¥å…·',
        epilog='''
ç¯„ä¾‹:
  python compress_images.py "D:\\Photos" --quality 50
  python compress_images.py "D:\\Photos" --quality 80 --overwrite --keep-exif
  python compress_images.py "D:\\Photos" -q 70 -w 8 -d 1
  python compress_images.py "D:\\Photos" --dry-run
        '''
    )
    parser.add_argument('-q', '--quality', type=int, default=70,
                        help='å£“ç¸®å“è³ª 1-100 (é è¨­: 70)')
    parser.add_argument('-o', '--overwrite', action='store_true',
                        help='è¦†è“‹å·²å­˜åœ¨çš„å£“ç¸®æª”')
    parser.add_argument('-e', '--keep-exif', action='store_true',
                        help='ä¿ç•™ EXIF è³‡è¨Š (GPSã€æ‹æ”æ™‚é–“ç­‰)')

    args = parser.parse_args()

    directory = resolve_directory(args)
    if not directory:
        return
    if not validate_quality(args.quality):
        return

    root_path = Path(directory)
    if not root_path.exists():
        logger.error(f"ç›®éŒ„ä¸å­˜åœ¨: {directory}")
        return

    logger.info(f"\nåœ–ç‰‡å£“ç¸®å·¥å…· v4.0")
    logger.info(f"ç›®æ¨™ç›®éŒ„: {directory}")
    logger.info(f"å£“ç¸®å“è³ª: {args.quality}%")
    logger.info(f"è¦†è“‹æ¨¡å¼: {'æ˜¯' if args.overwrite else 'å¦'}")
    logger.info(f"ä¿ç•™EXIF: {'æ˜¯' if args.keep_exif else 'å¦'}")
    logger.info(f"æœ€å¤§æ·±åº¦: {'ç„¡é™' if args.max_depth is None else args.max_depth}")
    logger.info(f"Process æ•¸: {args.workers}")
    if args.dry_run:
        logger.info("æ¨¡å¼: ğŸ” DRY-RUN (é è¦½)")
    logger.info("=" * 60)

    files = collect_files(root_path, SUPPORTED_FORMATS, max_depth=args.max_depth)

    worker = partial(
        compress_image,
        quality=args.quality,
        overwrite=args.overwrite,
        keep_exif=args.keep_exif,
        dry_run=args.dry_run,
    )

    summary = run_pipeline(files, worker, args.workers, args.dry_run, label="å£“ç¸®")
    print_summary(summary, success_label="æˆåŠŸå£“ç¸®", skip_label="è·³é(å·²å­˜åœ¨/BMP)")


if __name__ == "__main__":
    main()
