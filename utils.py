"""
åœ–ç‰‡è™•ç†å·¥å…· - å…±ç”¨æ¨¡çµ„

æä¾›ä¸¦è¡Œè™•ç†ç®¡ç·šã€çµ±è¨ˆå½™æ•´ã€CLI å…±ç”¨å…ƒä»¶ç­‰åŠŸèƒ½ã€‚
ä½¿ç”¨ ProcessPoolExecutor æ”¯æ´å¤šæ ¸ CPU åŠ é€Ÿã€‚
"""

import logging
from dataclasses import dataclass
from pathlib import Path
from concurrent.futures import ProcessPoolExecutor, as_completed
from typing import Callable
import argparse

# è¨­å®š Logger
logger = logging.getLogger("img_tools")

def setup_logger(verbose: bool = False):
    """åˆå§‹åŒ– Logger"""
    level = logging.DEBUG if verbose else logging.INFO
    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(message)s')
    handler.setFormatter(formatter)
    logger.setLevel(level)
    
    # é¿å…é‡è¤‡ add handler
    if not logger.handlers:
        logger.addHandler(handler)


@dataclass
class FileResult:
    """å–®ä¸€æª”æ¡ˆè™•ç†çµæœ (immutable per-file)"""
    status: str  # 'success', 'skipped', 'failed', 'size_skip', 'dry_run'
    message: str
    original_size: int = 0
    new_size: int = 0


@dataclass
class ProcessingSummary:
    """æ‰¹æ¬¡è™•ç†çµ±è¨ˆæ‘˜è¦"""
    success: int = 0
    skipped: int = 0
    failed: int = 0
    size_skip: int = 0
    total_original: int = 0
    total_new: int = 0


def format_size(size_bytes: int) -> str:
    """å°‡ bytes è½‰ç‚ºäººé¡å¯è®€æ ¼å¼"""
    if size_bytes < 1024:
        return f"{size_bytes} B"
    elif size_bytes < 1024 * 1024:
        return f"{size_bytes / 1024:.1f} KB"
    elif size_bytes < 1024 * 1024 * 1024:
        return f"{size_bytes / (1024 * 1024):.1f} MB"
    else:
        return f"{size_bytes / (1024 * 1024 * 1024):.2f} GB"


def collect_files(
    directory: Path,
    supported_formats: set[str],
    exclude_dirs: set[str] | None = None,
    max_depth: int | None = None,
) -> list[Path]:
    """
    æ”¶é›†ç›®éŒ„åŠå­ç›®éŒ„ä¸­æ‰€æœ‰ç¬¦åˆæ ¼å¼çš„æª”æ¡ˆ

    Args:
        directory: ç›®æ¨™ç›®éŒ„
        supported_formats: æ”¯æ´çš„å‰¯æª”åé›†åˆ (å«é»è™Ÿ)
        exclude_dirs: è¦æ’é™¤çš„ç›®éŒ„åç¨±é›†åˆ
        max_depth: æœ€å¤§éè¿´æ·±åº¦ (0 ä»£è¡¨åªæƒæç›®æ¨™ç›®éŒ„ä¸é€²å…¥å­ç›®éŒ„ï¼ŒNone ä»£è¡¨ç„¡é™æ·±)
    """
    files = []
    for f in directory.rglob('*'):
        if not f.is_file():
            continue
            
        try:
            rel = f.relative_to(directory)
            depth = len(rel.parts) - 1
            
            # æ·±åº¦æª¢æŸ¥
            if max_depth is not None and depth > max_depth:
                continue
                
            # æ’é™¤æŒ‡å®šç›®éŒ„
            if exclude_dirs and any(part in exclude_dirs for part in rel.parts):
                continue
                
        except ValueError:
            continue
            
        if f.suffix.lower() not in supported_formats:
            continue
            
        files.append(f)
    return files


def run_pipeline(
    files: list[Path],
    worker_fn: Callable[[Path], FileResult],
    workers: int,
    dry_run: bool = False,
    label: str = "è™•ç†",
) -> ProcessingSummary:
    """
    ä¸¦è¡Œè™•ç†æª”æ¡ˆç®¡ç·š (ProcessPoolExecutor)
    """
    summary = ProcessingSummary()
    total = len(files)

    if dry_run:
        logger.info(f"[DRY-RUN] æ‰¾åˆ° {total} å¼µåœ–ç‰‡ï¼Œé è¦½æ¨¡å¼ï¼ˆä¸æœƒå¯¦éš›{label}ï¼‰...")
    else:
        logger.info(f"æ‰¾åˆ° {total} å¼µåœ–ç‰‡ï¼Œé–‹å§‹{label}...")
    logger.info("=" * 60)

    if total == 0:
        return summary

    # ä½¿ç”¨ ProcessPoolExecutor å……åˆ†åˆ©ç”¨å¤šæ ¸ (Pillow æ“ä½œæ˜¯ CPU-bound)
    with ProcessPoolExecutor(max_workers=workers) as executor:
        futures = {executor.submit(worker_fn, f): f for f in files}

        for i, future in enumerate(as_completed(futures), 1):
            result = future.result()
            
            if result.status == 'failed':
                logger.error(f"[{i}/{total}] {result.message}")
            elif result.status == 'skipped':
                logger.debug(f"[{i}/{total}] {result.message}")
                # è‹¥éœ€è¦å…¨å°å‡ºï¼Œå¯ä¾å–œå¥½èª¿æ•´ log level
                if verbose_or_not_impl := True: # é€™è£¡è®“å®ƒç¶­æŒåŸæœ¬è¡Œç‚ºï¼Œå…¨å°
                    logger.info(f"[{i}/{total}] {result.message}")
            else:
                logger.info(f"[{i}/{total}] {result.message}")

            if result.status == 'success':
                summary.success += 1
                summary.total_original += result.original_size
                summary.total_new += result.new_size
            elif result.status in ('skipped', 'dry_run'):
                summary.skipped += 1
            elif result.status == 'size_skip':
                summary.size_skip += 1
            else:
                summary.failed += 1

    return summary


def print_summary(
    summary: ProcessingSummary,
    success_label: str = "æˆåŠŸè™•ç†",
    skip_label: str = "è·³é(å·²å­˜åœ¨/å·²è™•ç†)",
    after_label: str = "è™•ç†å¾Œ",
) -> None:
    """å°å‡ºè™•ç†çµæœæ‘˜è¦"""
    logger.info("=" * 60)
    logger.info("è™•ç†å®Œæˆ!")
    logger.info(f"  {success_label}: {summary.success}")
    logger.info(f"  {skip_label}: {summary.skipped}")
    if summary.size_skip > 0:
        logger.info(f"  è·³é(è™•ç†å¾Œè®Šå¤§): {summary.size_skip}")
    logger.info(f"  å¤±æ•—: {summary.failed}")

    if summary.total_original > 0:
        saved = summary.total_original - summary.total_new
        pct = (saved / summary.total_original) * 100
        logger.info(f"\n  ğŸ“Š ç©ºé–“çµ±è¨ˆ:")
        logger.info(f"     åŸå§‹ç¸½å¤§å°: {format_size(summary.total_original)}")
        logger.info(f"     {after_label}ç¸½å¤§å°: {format_size(summary.total_new)}")
        logger.info(f"     ç¸½å…±ç¯€çœ: {format_size(saved)} ({pct:.1f}%)")


def create_base_parser(description: str, epilog: str) -> argparse.ArgumentParser:
    """å»ºç«‹å«å…±ç”¨åƒæ•¸çš„ ArgumentParser"""
    parser = argparse.ArgumentParser(
        description=description,
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=epilog,
    )
    parser.add_argument('directory', nargs='?', help='ç›®æ¨™ç›®éŒ„è·¯å¾‘')
    parser.add_argument('-w', '--workers', type=int, default=4,
                        help='ä¸¦è¡Œè™•ç†ç¨‹åºçš„æ•¸é‡ (é è¨­: 4)')
    parser.add_argument('-n', '--dry-run', action='store_true',
                        help='é è¦½æ¨¡å¼ï¼šåƒ…åˆ—å‡ºå¾…è™•ç†æª”æ¡ˆï¼Œä¸å¯¦éš›è™•ç†')
    parser.add_argument('-d', '--max-depth', type=int, default=None,
                        help='æœ€å¤§éè¿´æ·±åº¦ (0=ä¸é€²å…¥å­ç›®éŒ„, æœªæŒ‡å®š=ç„¡é™)')
    return parser


def resolve_directory(args) -> str | None:
    """è§£æç›®éŒ„è·¯å¾‘ (æ”¯æ´äº’å‹•æ¨¡å¼)ï¼Œå›å‚³ None è¡¨ç¤ºä½¿ç”¨è€…æœªè¼¸å…¥"""
    if not args.directory:
        args.directory = input("è«‹è¼¸å…¥ç›®æ¨™ç›®éŒ„è·¯å¾‘: ").strip()
        if not args.directory:
            logger.error("æœªè¼¸å…¥ç›®éŒ„ï¼Œç¨‹å¼çµæŸ")
            return None
    return args.directory


def validate_quality(quality: int) -> bool:
    """é©—è­‰ quality åƒæ•¸ç¯„åœ"""
    if not 1 <= quality <= 100:
        logger.error("éŒ¯èª¤: quality å¿…é ˆåœ¨ 1-100 ä¹‹é–“")
        return False
    return True
